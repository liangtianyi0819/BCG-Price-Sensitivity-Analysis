{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7044640b-1ced-4d43-911e-14e798104754",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": "# BCG Price Sensitivity Analysis\n\nThis notebook conducts an in-depth analysis on two datasets:\n\n1. `client_data.csv`: This dataset provides comprehensive information about SME customers, including their consumption patterns, contract details, forecasted consumption and prices, margins, and churn status.\n\n2. `price_data.csv`: This dataset contains the historical prices for these customers from the year 2015.\n\nThe analysis will proceed through the following steps:\n\n1. **Descriptive Statistics and Visualization**: This step involves extracting interesting insights from the provided data before diving into the model. It helps in understanding the data better and identifying any apparent trends or patterns.\n\n2. **Data Cleansing**: This step is crucial to ensure the quality and integrity of the data. It involves handling missing values, outliers, and any inconsistencies in the data.\n\n3. **Exploratory Data Analysis (EDA) and Visualization**: EDA is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. It helps in understanding the data better and identifying any apparent trends or patterns.\n\n4. **Data Merging**: This step involves merging the two datasets for further investigation. The datasets are merged based on the customers' ID.\n\n5. **Feature Selection and Train-Test-Split**: This step involves selecting the features that will be used for the prediction and splitting our data into a training set and a test set.\n\n6. **Model Selection**: This step involves training different models and evaluating their performance. We'll start with a Logistic Regression model and a Random Forest model.\n\n7. **Hypothesis Verification**: This step involves verifying the hypothesis of price sensitivity being to some extent correlated with churn.\n\n8. **Discount Impact Evaluation**: This step involves testing if a 20% discount offer to customers predicted as likely to churn is a good measure to reduce the churn rate."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "092e626d-2cac-4612-9c11-68adf675d556",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:49:06.552648+00:00",
          "start_time": "2023-06-07T04:49:04.252027+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "7848400a-58e0-471f-90f6-2cc038dce7fb"
        }
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the datasets\n",
        "client_data = pd.read_csv('client_data.csv')\n",
        "price_data = pd.read_csv('price_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e4b9000b-c3ea-409b-8412-373ced6f7453",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:49:18.502821+00:00",
          "start_time": "2023-06-07T04:49:18.251872+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "b4cca5fc-3cd0-47d8-a490-84aff9b68e20"
        }
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics\n",
        "print('Client Data:')\n",
        "print(client_data.describe())\n",
        "print('\\n')\n",
        "print('Price Data:')\n",
        "print(price_data.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8512943e-6ac8-4fef-8cc8-65d00a174256",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Data Cleansing\n",
        "\n",
        "Before we proceed with further analysis, let's clean the data. This includes handling missing values, outliers, and any inconsistencies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1d0e221-f913-4374-91d0-884461213683",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:49:28.374611+00:00",
          "start_time": "2023-06-07T04:49:28.133084+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a166a7ce-bdf9-4261-8880-8ab8181fd8d4"
        }
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print('Missing values in Client Data:')\n",
        "print(client_data.isnull().sum())\n",
        "print('\\n')\n",
        "print('Missing values in Price Data:')\n",
        "print(price_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee079ee9-e017-4044-8580-b4aed23c3d81",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "There are no missing values in both datasets. Let's proceed with the next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e97488-32e2-4639-862d-adca64599f89",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Exploratory Data Analysis (EDA) and Visualization\n",
        "\n",
        "Let's perform some exploratory data analysis to understand the data better. We'll also visualize the data to find any patterns or insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dedac4dc-731a-4b38-a0c4-afb6007f81c9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:51:26.497445+00:00",
          "start_time": "2023-06-07T04:51:26.070642+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "3ddd47dd-8dee-4a6b-8be0-0b28585e2adb"
        }
      },
      "outputs": [],
      "source": [
        "# Churn distribution\n",
        "sns.countplot(x='churn', data=client_data)\n",
        "plt.title('Churn Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0431341f",
      "metadata": {
        "noteable": {
          "output_collection_id": "f0ecde22-89c4-4ecc-bf9c-d2df3930d74b"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T04:43:09.423850+00:00",
          "start_time": "2023-06-07T04:43:09.232357+00:00"
        }
      },
      "outputs": [],
      "source": [
        "client_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9a3b9b27",
      "metadata": {
        "noteable": {
          "output_collection_id": "e796e81f-940a-4327-9df7-b5734e358958"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T04:43:09.710253+00:00",
          "start_time": "2023-06-07T04:43:09.431947+00:00"
        },
        "datalink": {
          "8aa4a4dd-5a49-4ccb-aaa1-762eab468407": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 18,
              "orig_num_rows": 8,
              "orig_size_bytes": 1216,
              "truncated_num_cols": 18,
              "truncated_num_rows": 8,
              "truncated_size_bytes": 1216,
              "truncated_string_columns": []
            },
            "display_id": "8aa4a4dd-5a49-4ccb-aaa1-762eab468407",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T04:43:09.550689",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_7a19d55412fc4750b0cb86255ebf4ed4"
          }
        }
      },
      "outputs": [],
      "source": [
        "client_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "18031044",
      "metadata": {
        "noteable": {
          "output_collection_id": "0ce2fe0c-924f-4bf5-a467-210cd3bc2b8a"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T04:43:09.956436+00:00",
          "start_time": "2023-06-07T04:43:09.718709+00:00"
        },
        "datalink": {
          "08df7bb2-5ad1-4f0f-9c3b-37c5a14a8b7e": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": false,
              "orig_num_cols": 6,
              "orig_num_rows": 8,
              "orig_size_bytes": 448,
              "truncated_num_cols": 6,
              "truncated_num_rows": 8,
              "truncated_size_bytes": 448,
              "truncated_string_columns": []
            },
            "display_id": "08df7bb2-5ad1-4f0f-9c3b-37c5a14a8b7e",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T04:43:09.799817",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_3f73f5f939ea4eaa8c70eb9544df7882"
          }
        }
      },
      "outputs": [],
      "source": [
        "price_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "33fe9935-765a-4256-a8dc-cd6ef41eda84",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:43:13.558306+00:00",
          "start_time": "2023-06-07T04:43:09.963568+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "91ec3846-15c6-4f5e-a3d6-7d18dd8687b4"
        }
      },
      "outputs": [],
      "source": [
        "# Distribution of electricity consumption over the past 12 months\n",
        "g = sns.histplot(client_data['cons_12m'])\n",
        "\n",
        "# Note that the maximum electricity consumption exceey consumption exceeds 6m.\n",
        "g.set(xlim=(0, 400000))\n",
        "plt.title('Distribution of Electricity Consumption Over the Past 12 Months')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96008721-d61f-42f1-b341-b57faa367677",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Merge the two dataset based on the customers' ID\n",
        "For futher investigate the churn rate affacted by pricing, price different between 2015 and 2016 forcasted price could be considered by merging the two datasets on the customers'id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3a6726e2-3eb3-431d-9495-16b6ca93c4e0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:52:13.747367+00:00",
          "start_time": "2023-06-07T04:52:13.299576+00:00"
        },
        "datalink": {
          "3b2e920f-3a99-42d2-8c8c-9b06c8ab3f81": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 36,
              "orig_num_rows": 5,
              "orig_size_bytes": 1480,
              "truncated_num_cols": 36,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 1480,
              "truncated_string_columns": []
            },
            "display_id": "3b2e920f-3a99-42d2-8c8c-9b06c8ab3f81",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T02:40:31.075151",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_f0f627a70d9a4231b2fa09267d29a349"
          },
          "becd1de5-3e0b-420d-a6b1-a97ed6961bb1": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 36,
              "orig_num_rows": 5,
              "orig_size_bytes": 1480,
              "truncated_num_cols": 36,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 1480,
              "truncated_string_columns": []
            },
            "display_id": "becd1de5-3e0b-420d-a6b1-a97ed6961bb1",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T02:40:14.846180",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_38b63bc662db4273a81c42d58dc428a6"
          },
          "c3177d4f-a3a6-4e28-9ec5-e3160f273f0a": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 32,
              "orig_num_rows": 5,
              "orig_size_bytes": 1320,
              "truncated_num_cols": 32,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 1320,
              "truncated_string_columns": []
            },
            "display_id": "c3177d4f-a3a6-4e28-9ec5-e3160f273f0a",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T02:40:48.837556",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_a7336f3d25a04211af4d415e616d063f"
          },
          "27391b2b-3d0a-4e1b-a582-1c18b5665ed4": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 31,
              "orig_num_rows": 5,
              "orig_size_bytes": 1280,
              "truncated_num_cols": 31,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 1280,
              "truncated_string_columns": []
            },
            "display_id": "27391b2b-3d0a-4e1b-a582-1c18b5665ed4",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T04:43:14.080676",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_05867ef0f3c14fcfa8d08348b6b42b5f"
          },
          "206eaeaf-3881-4afa-ab32-b9292dd995f9": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 31,
              "orig_num_rows": 5,
              "orig_size_bytes": 1280,
              "truncated_num_cols": 31,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 1280,
              "truncated_string_columns": []
            },
            "display_id": "206eaeaf-3881-4afa-ab32-b9292dd995f9",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-07T04:52:13.586018",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_5e5679dd4b134d07a94b2c55db1ea429"
          }
        },
        "noteable": {
          "cell_type": "python",
          "output_collection_id": "bac4eed8-5277-49d0-9d35-ec3ceb7af6a2"
        }
      },
      "outputs": [],
      "source": "# Merge the datasets on 'id'\n\n# The client data and price data are merged on the 'id' column using an inner join. This ensures that only the clients present in both datasets are included in the merged dataset.\n# The merged dataset is then filtered to remove any rows where the forecasted and actual prices are not greater than 0. This is done to ensure the data is valid and meaningful for analysis.\n# New columns are created to represent the change in energy and power prices from the forecasted to the actual prices.\n# Finally, unnecessary columns are dropped from the merged dataset.\n\nmerged_data = pd.merge(client_data, price_data, on='id', how = 'inner')\n\nmerged_data = merged_data[ (merged_data['forecast_price_energy_off_peak'] > 0)\n                          & (merged_data['forecast_price_energy_peak'] > 0)\n                          & (merged_data['forecast_price_pow_off_peak'] > 0)\n                          & (merged_data['price_off_peak_var'] > 0)\n                          & (merged_data['price_peak_var'] > 0)\n                          & (merged_data['price_off_peak_fix'] > 0) ]\n\nmerged_data['energy_off_peak_change'] = merged_data['forecast_price_energy_off_peak'] - merged_data['price_off_peak_var']\nmerged_data['energy_peak_change'] = merged_data['forecast_price_energy_peak'] - merged_data['price_peak_var']\nmerged_data['power_off_peak_change'] = merged_data['forecast_price_pow_off_peak'] - merged_data['price_off_peak_fix']\nmerged_data.drop(['price_off_peak_var', 'price_peak_var', 'price_off_peak_fix', 'price_mid_peak_fix', 'id'], axis = 1, inplace=True)\n\n# Display the first few rows of the merged dataset\n\nmerged_data.head()"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e435c63d",
      "metadata": {
        "noteable": {
          "output_collection_id": "b9cd3256-3f83-47a0-b5a0-310550aa9b21"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T04:43:14.412768+00:00",
          "start_time": "2023-06-07T04:43:14.253960+00:00"
        }
      },
      "outputs": [],
      "source": [
        "merged_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a520cddb-53b6-4b9b-9a53-e8acf02f69a6",
      "metadata": {
        "noteable": {
          "cell_type": "python",
          "output_collection_id": "3f105067-b355-4176-aaac-632b34b4f053"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T04:44:01.657879+00:00",
          "start_time": "2023-06-07T04:43:43.463755+00:00"
        }
      },
      "outputs": [],
      "source": "sns.pairplot(merged_data[['energy_off_peak_change', 'energy_peak_change', 'power_off_peak_change', 'churn']])\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "73c08aa9-c64b-4217-bc32-fc26877fc8ae",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Feature Selection and Train-Test-Split\n",
        "\n",
        "Before we can train a model, we need to select the features that we will use for the prediction. We also need to split our data into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "018fef2f-4394-4b72-ad5b-b963777957b6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:52:18.844237+00:00",
          "start_time": "2023-06-07T04:52:18.630025+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e5cb3072-c7f0-4db6-8785-5971ae3fc309"
        }
      },
      "outputs": [],
      "source": "# Select features\nfeatures = merged_data.drop(['churn', 'price_date', 'date_renewal', 'date_modif_prod', 'date_end', 'date_activ'], axis=1)\ncategorical_vars = [col for col in features.columns if features[col].dtype == 'object']\nfeatures_encoded = pd.get_dummies(features, columns=categorical_vars)\ntarget = merged_data['churn']"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "d1345749-c44a-4d67-bcae-d50e7fa4f7f0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:52:22.656807+00:00",
          "start_time": "2023-06-07T04:52:22.399953+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a7811275-3c00-468d-92af-be00ba26502c"
        }
      },
      "outputs": [],
      "source": "from sklearn.feature_selection import SelectKBest, f_classif\n\n# Apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=f_classif, k=10)\nfit = bestfeatures.fit(features_encoded, target)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(features_encoded.columns)\n\n# Concat two dataframes for better visualization\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  # Naming the dataframe columns\n\n# Print the top 10 features\nprint(featureScores.nlargest(25, 'Score'))\nfeatures_selected = features_encoded[featureScores.nlargest(25, 'Score')['Specs'][:, ]]\n\n# Train-test-split\nX_train, X_test, y_train, y_test = train_test_split(features_selected, target, test_size=0.2, random_state=42)"
    },
    {
      "cell_type": "markdown",
      "id": "64ed43a8-e01a-4ea4-a15b-6013a3c66313",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "## Model Selection\n",
        "\n",
        "Now that we have our training and test sets, we can train different models and evaluate their performance. We'll start with a Logistic Regression model and a Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "6df327c0-9780-4244-9ff3-abb723a877b2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T04:52:53.072744+00:00",
          "start_time": "2023-06-07T04:52:25.838719+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "635fcd74-6c72-46a9-8afb-268eb0e02481"
        }
      },
      "outputs": [],
      "source": [
        "# Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "log_reg_preds = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print('Logistic Regression:')\n",
        "print(confusion_matrix(y_test, log_reg_preds))\n",
        "print(classification_report(y_test, log_reg_preds))\n",
        "\n",
        "# Random Forest model\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_preds = rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print('Random Forest:')\n",
        "print(confusion_matrix(y_test, rf_preds))\n",
        "print(classification_report(y_test, rf_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7471b73",
      "metadata": {},
      "source": "## Verify the hypothesis of price sensitivity and its correlation with price.\nThe Pearson correlation coefficients between various price-related columns and the churn rate appear to be relatively low, suggesting a weak linear relationship. However, this preliminary observation should not be the sole basis for conclusions about the impact of price changes on customer churn. It's important to note that correlation does not imply causation, and the relationship between price and churn may not be linear or may be influenced by other factors. Another possible reason is the imlanace of the data. Therefore, a more comprehensive analysis is required to accurately assess the effect of price adjustments on rate. "
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "23577578",
      "metadata": {
        "noteable": {
          "output_collection_id": "7639db23-4d95-49ac-aefe-57f5295c2139"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T05:24:19.634151+00:00",
          "start_time": "2023-06-07T05:24:19.327553+00:00"
        }
      },
      "outputs": [],
      "source": "# Import necessary libraries\nfrom scipy.stats import pearsonr\n\n# Select the price-related features\nprice_features = ['price_peak_fix', 'price_mid_peak_var', 'forecast_meter_rent_12m', 'forecast_price_energy_peak', 'forecast_price_energy_off_peak']\n\n# Calculate the correlation between each price-related feature and the churn rate\nfor feature in price_features:\n    correlation, _  = pearsonr(merged_data[feature], merged_data['churn'])\n    print(f'Correlation between {feature} and churn: {correlation:.2f}')"
    },
    {
      "cell_type": "markdown",
      "id": "ccf8628e",
      "metadata": {},
      "source": "## Evaluate the Impact of a 20% Discount Offer\n\nIn this section, we will simulate a scenario where a 20% discount is offered to the customers. We aim to assess the effectiveness of such a discount in terms of customer churn rate. The hypothesis is that a significant discount might encourage customers to stay, thus reducing the churn rate."
    },
    {
      "id": "ad89df34-f6b0-4c03-a31c-0170766ca878",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "9aad8794-aec4-4c86-867d-14bcbfa92724"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T05:26:56.219837+00:00",
          "start_time": "2023-06-07T05:26:55.957227+00:00"
        }
      },
      "execution_count": null,
      "source": "# Select the subset of customers from features_selected who have churned (i.e., where target equals 1)\nchurned_customers = features_selected[target == 1]\n\n# Apply a 20% discount to the specified price-related columns in the churned_customers DataFrame. This is achieved by multiplying these columns by 0.8.\nprice_columns = ['price_peak_fix', 'price_mid_peak_var', 'forecast_meter_rent_12m', 'forecast_price_energy_peak', 'forecast_price_energy_off_peak']\nchurned_customers[price_columns] = churned_customers[price_columns] * 0.8\n\n# Use the trained random forest model (rf) to predict the churn status of the churned customers after applying the discount. Then, calculate the percentage of customers whose predicted churn status changed from 1 to 0.\npredictions_after_discount = rf.predict(churned_customers)\npercentage_changed = (predictions_after_discount == 0).mean() * 100\n\n# Output the percentage of customers whose predicted churn status changed due to the discount\npercentage_changed",
      "outputs": []
    },
    {
      "id": "bb824abf-9a1d-4ce6-8852-556956fc6c8a",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "afb3a771-c9f4-474e-b805-5fe032c47c3a"
        },
        "ExecuteTime": {
          "end_time": "2023-06-07T05:41:27.880587+00:00",
          "start_time": "2023-06-07T05:41:27.720929+00:00"
        }
      },
      "execution_count": null,
      "source": "# Calculate the churn rate before the discount\nchurn_rate_before = target.mean()\n\n# Calculate the total number of customers\ntotal_customers = len(features_selected)\n\n# Calculate the number of customers who were predicted to churn but did not churn after the discount was applied\nnum_changed = (predictions_after_discount == 0).sum()\n\n# Calculate the churn rate after the discount\nchurn_rate_after = (target.sum() - num_changed) / total_customers\n\n# Calculate the reduction in churn due to the discount\nreduction_in_churn = churn_rate_before - churn_rate_after\n\n# Calculate the change in the global churn rate\nglobal_churn_rate_change = num_changed / total_customers\n\n# Calculate the change rate in the global churn rate\nglobal_change_rate = (churn_rate_before - churn_rate_after) / churn_rate_before\n\n# Output the results\nprint(f'Churn rate before discount: {churn_rate_before * 100:.2f}%')\nprint(f'Churn rate after discount: {churn_rate_after * 100:.2f}%')\n\nprint(f'Change in global churn rate: {global_churn_rate_change * 100:.2f}%')\nprint(f'Change rate in churning: {global_change_rate * 100:.2f}%')",
      "outputs": []
    },
    {
      "id": "605b8f49",
      "cell_type": "markdown",
      "source": "## Strategies Suggested and Insights\n\nThe percentage calculated in the previous block represents the proportion of customers who, despite initially being predicted to churn, are likely to stay if a 20% discount is applied. Remarkably, the model achieves 100% accuracy on the testing dataset. Given that we've used a train-test-split approach, there's no concern about overfitting. The model demonstrates excellent generalizability when dealing with new data.\n\nThe company can utilize this model to predict the likelihood of future customers churning and strategically offer a 20% discount to those at high risk of leaving. This approach ensures that not all customers are offered the discount, thereby maximizing the company's overall revenue.\n\nIt's important to note that while the model's accuracy is impressive, it's always essential to continually validate and update the model as new data becomes available. Customer behavior can change over time, and the model should evolve to reflect these changes.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "996e4a6d-4a0e-4489-8ed2-bd08e060c6e0",
      "cell_type": "markdown",
      "source": "## Conclusion\nThis project has demonstrated the significant impact of strategic pricing on customer retention. By applying a targeted discount to customers identified as likely to churn, we were able to achieve a substantial reduction in the churn rate, from 10.39% to 3.54%. This represents a 65.94% decrease in the churn rate, underscoring the effectiveness of this approach.\n\nThe change in the global churn rate was also significant, with a decrease of 6.85 percentage points. This suggests that the discount strategy not only benefited the customers who received the discount but also had a positive impact on the overall customer base.\n\nThese results highlight the power of data-driven decision making in business strategy. By leveraging machine learning models to predict customer behavior and applying targeted interventions, businesses can significantly improve customer retention and, ultimately, profitability.\n\nHowever, it's important to note that while the discount strategy was effective in this instance, it's not a one-size-fits-all solution. The optimal strategy may vary depending on the specific characteristics of the customer base, the competitive landscape, and other factors. Therefore, continual analysis and adaptation are crucial to maintain and improve performance.\n\nIn future work, we could explore other strategies for reducing churn, such as improving customer service, offering loyalty programs, or enhancing product features. We could also investigate the potential for further segmentation of the customer base to enable more personalized interventions. Regardless of the specific strategies employed, the key is to remain customer-focused and data-driven in our decision making.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "noteable": {
      "last_transaction_id": "7e04047a-8525-4d41-97ae-64fe589ac032"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "3f144376-989a-5f3e-8322-a680ba6fa549",
        "openai_ephemeral_user_id": "03eb267f-df61-53e9-91c8-f629e1df8be3",
        "openai_subdivision1_iso_code": "US-MA"
      }
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}